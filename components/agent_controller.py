# components/agent_controller.py
from typing import List, Dict, Any, Optional, Type
from langchain_ollama import ChatOllama
from langchain.tools import BaseTool
from langchain.agents import create_react_agent, AgentExecutor
from langchain.prompts import PromptTemplate
from langchain.memory import ConversationBufferWindowMemory
from langchain_core.messages import HumanMessage, AIMessage
from langchain.callbacks.manager import (
    AsyncCallbackManagerForToolRun,
    CallbackManagerForToolRun,
)
import requests
from pydantic import Field

class RAGTool(BaseTool):
    """Herramienta para b√∫squeda RAG"""
    
    # ‚úÖ Campos con anotaciones de tipo correctas
    name: str = Field(default="search_documents")
    description: str = Field(default="""
    Busca informaci√≥n en la base de conocimientos de documentos acad√©micos.
    Usa esta herramienta cuando el usuario pregunte sobre conceptos, teor√≠as, 
    metodolog√≠as que puedan estar en los documentos almacenados.
    Input: Una consulta de texto sobre el contenido acad√©mico.
    """)
    rag_system: Any = Field(description="Sistema RAG para b√∫squeda de documentos")
    
    def __init__(self, rag_system, **kwargs):
        super().__init__(rag_system=rag_system, **kwargs)
    
    def _run(
        self, 
        query: str, 
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """Ejecuta b√∫squeda RAG"""
        try:
            results = self.rag_system.hybrid_search(query, k=3)
            
            if not results:
                return "No encontr√© informaci√≥n relevante en los documentos para esta consulta."
            
            # Formatear resultados
            context = "üìö Informaci√≥n encontrada en los documentos:\n\n"
            for i, result in enumerate(results, 1):
                context += f"**{i}. [{result['metadata'].get('section', 'Sin secci√≥n')}]** "
                context += f"(Relevancia: {result['similarity_score']:.2f})\n"
                context += f"{result['content'][:400]}...\n\n"
                
                # Agregar informaci√≥n del documento fuente
                if 'file_name' in result['metadata']:
                    context += f"üìÑ *Fuente: {result['metadata']['file_name']}*\n"
                if 'authors' in result['metadata']:
                    context += f"‚úçÔ∏è *Autores: {result['metadata']['authors']}*\n"
                context += "---\n\n"
            
            return context
            
        except Exception as e:
            return f"‚ùå Error en b√∫squeda de documentos: {str(e)}"
    
    async def _arun(
        self,
        query: str,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
    ) -> str:
        """Versi√≥n as√≠ncrona de la b√∫squeda RAG"""
        # Para simplicidad, llamamos la versi√≥n s√≠ncrona
        return self._run(query, run_manager=run_manager)

class WebSearchTool(BaseTool):
    """Herramienta para b√∫squeda web"""
    
    # ‚úÖ Campos con anotaciones de tipo correctas
    name: str = Field(default="search_web")
    description: str = Field(default="""
    Busca informaci√≥n actualizada en Internet.
    Usa esta herramienta SOLO cuando el usuario solicite expl√≠citamente 
    informaci√≥n actual, noticias recientes, o datos que no est√°n en 
    los documentos almacenados.
    Input: Una consulta sobre informaci√≥n actual o reciente.
    """)
    
    def _run(
        self, 
        query: str, 
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """Simula b√∫squeda web (reemplazar con Tavily API real si es necesario)"""
        # Para este ejemplo, simulamos una b√∫squeda web
        # En implementaci√≥n real, integrar con Tavily API
        return f"""üåê B√∫squeda web realizada para: "{query}"

üìã **Nota importante**: Esta es una b√∫squeda simulada para demostraci√≥n. 

üîß **Para habilitar b√∫squeda web real**:
1. Registrarse en Tavily API (tavily.com)
2. Obtener API key gratuita
3. Configurar en archivo .env: TAVILY_API_KEY=tu_key
4. Descomentar c√≥digo de integraci√≥n en esta herramienta

üí° **Sugerencia**: Reformula tu pregunta para buscar en los documentos acad√©micos cargados, 
donde tengo acceso completo al contenido."""
    
    async def _arun(
        self,
        query: str,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
    ) -> str:
        """Versi√≥n as√≠ncrona de la b√∫squeda web"""
        return self._run(query, run_manager=run_manager)

class DirectAnswerTool(BaseTool):
    """Herramienta para respuestas directas"""
    
    # ‚úÖ Campos con anotaciones de tipo correctas
    name: str = Field(default="direct_answer")
    description: str = Field(default="""
    Responde directamente preguntas generales, saludos, o consultas que no requieren 
    b√∫squeda en documentos espec√≠ficos.
    Usa esta herramienta para: saludos, preguntas sobre el sistema, 
    consultas generales de conocimiento com√∫n.
    Input: Pregunta general o saludo.
    """)
    
    def _run(
        self, 
        query: str, 
        run_manager: Optional[CallbackManagerForToolRun] = None
    ) -> str:
        """Proporciona respuestas directas para consultas generales"""
        query_lower = query.lower()
        
        # Detectar tipos de consultas
        if any(greeting in query_lower for greeting in ['hola', 'hello', 'hi', 'buenas', 'saludos']):
            return """¬°Hola! üëã Soy tu asistente acad√©mico especializado en an√°lisis de documentos IEEE. 

üéØ **Puedo ayudarte con**:
- Buscar informaci√≥n espec√≠fica en tus documentos cargados
- Analizar metodolog√≠as y resultados de investigaci√≥n
- Encontrar referencias y citas relevantes
- Explicar conceptos t√©cnicos presentes en los papers

üìù **Ejemplos de preguntas**:
- "¬øQu√© metodolog√≠as proponen los autores?"
- "¬øCu√°les son los principales resultados experimentales?"
- "¬øQui√©n escribi√≥ sobre machine learning?"

¬°Hazme cualquier pregunta sobre tus documentos acad√©micos!"""
        
        elif any(word in query_lower for word in ['gracias', 'thanks', 'thank you']):
            return "¬°De nada! üòä Estoy aqu√≠ para ayudarte con cualquier consulta sobre tus documentos acad√©micos."
        
        elif any(word in query_lower for word in ['ayuda', 'help', 'c√≥mo', 'how']):
            return """ü§ñ **Gu√≠a de uso del asistente**:

1Ô∏è‚É£ **Sube documentos**: Usa la barra lateral para cargar PDFs
2Ô∏è‚É£ **Haz preguntas espec√≠ficas**: Pregunta sobre contenido, autores, metodolog√≠as
3Ô∏è‚É£ **Explora resultados**: Revisa las fuentes que cito en mis respuestas

üí° **Consejos para mejores resultados**:
- S√© espec√≠fico en tus preguntas
- Menciona t√©rminos t√©cnicos relevantes
- Pregunta sobre aspectos concretos de los papers

¬øHay algo espec√≠fico sobre lo que te gustar√≠a preguntar?"""
        
        else:
            return f"""Entiendo que preguntas sobre: "{query}"

Para darte la mejor respuesta posible, necesito buscar en tus documentos acad√©micos. 
¬øPodr√≠as reformular tu pregunta de manera m√°s espec√≠fica sobre el contenido de los papers?

üí° **Ejemplo**: En lugar de preguntas muy generales, puedes preguntar:
- "¬øQu√© algoritmos de machine learning mencionan los documentos?"
- "¬øCu√°les son las limitaciones identificadas en los estudios?"
- "¬øQu√© trabajos futuros proponen los autores?"
"""
    
    async def _arun(
        self,
        query: str,
        run_manager: Optional[AsyncCallbackManagerForToolRun] = None,
    ) -> str:
        """Versi√≥n as√≠ncrona de respuesta directa"""
        return self._run(query, run_manager=run_manager)

class AgentController:
    """Controlador principal del agente conversacional"""
    
    def __init__(self, rag_system, model_name: str = "llama3.2:3b"):
        self.rag_system = rag_system
        
        # Inicializar LLM (Ollama)
        self.llm = ChatOllama(
            model=model_name,
            temperature=0.1,
            num_predict=1024,
            # Configuraciones adicionales para mejor rendimiento
            top_k=10,
            top_p=0.9,
        )
        
        # Crear herramientas con la sintaxis correcta
        self.tools = [
            RAGTool(rag_system=rag_system),
            WebSearchTool(),
            DirectAnswerTool()
        ]
        
        # Configurar memoria temporal
        self.memory = ConversationBufferWindowMemory(
            k=5,  # Mantener √∫ltimas 5 interacciones
            return_messages=True,
            memory_key="chat_history"
        )
        
        # Crear agente
        self.agent = self._create_agent()
        
        # Crear executor
        self.agent_executor = AgentExecutor(
            agent=self.agent,
            tools=self.tools,
            memory=self.memory,
            verbose=True,
            max_iterations=3,
            handle_parsing_errors=True,
            early_stopping_method="generate"
        )
    
    def _create_agent(self):
        """Crea el agente ReactAgent con prompt optimizado"""
        prompt_template = """Eres un asistente acad√©mico experto especializado en an√°lisis de documentos IEEE y papers de investigaci√≥n.

HERRAMIENTAS DISPONIBLES:
{tools}

NOMBRES DE HERRAMIENTAS: {tool_names}

INSTRUCCIONES ESPEC√çFICAS:
1. üîç Para preguntas sobre contenido acad√©mico espec√≠fico ‚Üí usa "search_documents"
2. üåê Para informaci√≥n actual/noticias ‚Üí usa "search_web" SOLO si se solicita expl√≠citamente
3. üí¨ Para saludos y preguntas generales ‚Üí usa "direct_answer"
4. üìö SIEMPRE cita las fuentes cuando uses search_documents
5. üéØ Si no encuentras informaci√≥n espec√≠fica, sugiere reformular la pregunta

FORMATO DE RESPUESTA OBLIGATORIO:
Thought: [Analiza qu√© herramienta necesitas usar y por qu√©]
Action: [nombre_exacto_de_herramienta]
Action Input: [texto_para_la_herramienta]
Observation: [resultado de la herramienta]
... (repite Thought/Action/Action Input/Observation si necesitas m√°s herramientas)
Thought: I now know the final answer
Final Answer: [respuesta final completa y √∫til para el usuario]

CONTEXTO DE CONVERSACI√ìN:
{chat_history}

PREGUNTA DEL USUARIO: {input}

Comienza tu an√°lisis:
{agent_scratchpad}"""
        
        prompt = PromptTemplate.from_template(prompt_template)
        
        return create_react_agent(
            llm=self.llm,
            tools=self.tools,
            prompt=prompt
        )
    
    def chat(self, message: str, session_id: str = "default") -> str:
        """Interfaz principal de chat"""
        try:
            # Ejecutar agente
            response = self.agent_executor.invoke({
                "input": message,
                "chat_history": self.memory.chat_memory.messages[-10:]  # √öltimos 10 mensajes
            })
            
            # Extraer respuesta
            if isinstance(response, dict) and "output" in response:
                answer = response["output"]
            else:
                answer = str(response)
            
            # Limpiar respuesta si es necesario
            if "Final Answer:" in answer:
                answer = answer.split("Final Answer:")[-1].strip()
            
            return answer
            
        except Exception as e:
            error_msg = f"Error procesando consulta: {str(e)}"
            print(f"üîß Debug - {error_msg}")
            
            # Respuesta de fallback m√°s √∫til
            return """ü§î Disculpa, tuve un problema t√©cnico procesando tu consulta. 

üí° **Puedes intentar**:
- Reformular tu pregunta de manera m√°s espec√≠fica
- Verificar que hay documentos cargados en el sistema
- Hacer una pregunta m√°s simple primero

üîß **O preg√∫ntame sobre**:
- Contenido espec√≠fico de tus documentos
- Metodolog√≠as mencionadas en los papers
- Resultados experimentales
- Autores y referencias

¬øTe gustar√≠a intentar con una pregunta diferente?"""
    
    def clear_memory(self):
        """Limpia la memoria de conversaci√≥n"""
        self.memory.clear()
        print("üßπ Memoria de conversaci√≥n limpiada")
    
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """Obtiene historial de conversaci√≥n"""
        history = []
        for message in self.memory.chat_memory.messages:
            if isinstance(message, HumanMessage):
                history.append({"role": "user", "content": message.content})
            elif isinstance(message, AIMessage):
                history.append({"role": "assistant", "content": message.content})
        
        return history
    
    def get_agent_stats(self) -> Dict[str, Any]:
        """Estad√≠sticas del agente"""
        return {
            "tools_available": len(self.tools),
            "tool_names": [tool.name for tool in self.tools],
            "memory_size": len(self.memory.chat_memory.messages),
            "model_name": self.llm.model,
            "temperature": self.llm.temperature
        }

def check_ollama_connection(model_name: str = "llama3.2:3b") -> bool:
    """Verifica que Ollama est√© funcionando"""
    try:
        # Verificar si Ollama est√° corriendo
        response = requests.get("http://localhost:11434/api/tags", timeout=5)
        if response.status_code == 200:
            models = response.json().get('models', [])
            model_names = [model['name'] for model in models]
            
            if model_name in model_names:
                print(f"‚úÖ Ollama conectado. Modelo {model_name} disponible.")
                return True
            else:
                print(f"‚ùå Modelo {model_name} no encontrado.")
                print(f"üìã Modelos disponibles: {model_names}")
                print(f"üí° Para instalar: ollama pull {model_name}")
                return False
        else:
            print("‚ùå Ollama no est√° respondiendo en puerto 11434")
            return False
            
    except requests.exceptions.ConnectionError:
        print("‚ùå No se puede conectar con Ollama")
        print("üîß Verifica que Ollama est√© instalado y ejecut√°ndose:")
        print("1. Instala desde: https://ollama.com/download")
        print("2. Ejecuta: ollama serve")
        print(f"3. Instala modelo: ollama pull {model_name}")
        return False
    except Exception as e:
        print(f"‚ùå Error verificando Ollama: {e}")
        return False

def test_agent_tools():
    """Funci√≥n de prueba para verificar que las herramientas funcionan"""
    print("üß™ Probando definici√≥n de herramientas...")
    
    try:
        # Test b√°sico de creaci√≥n de herramientas
        rag_tool = RAGTool(rag_system=None)
        web_tool = WebSearchTool()
        direct_tool = DirectAnswerTool()
        
        print(f"‚úÖ RAGTool: {rag_tool.name}")
        print(f"‚úÖ WebSearchTool: {web_tool.name}")
        print(f"‚úÖ DirectAnswerTool: {direct_tool.name}")
        print("‚úÖ Todas las herramientas creadas correctamente")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error en herramientas: {e}")
        return False

if __name__ == "__main__":
    # Test b√°sico
    test_agent_tools()